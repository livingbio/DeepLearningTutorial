{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine, cdist\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('raw_sentences.txt') as f:\n",
    "    sentences = f.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 用 <unk> 取代罕見字\n",
    "c = Counter(sentences.split())\n",
    "words = [w if c[w] > 2 else '<unk>' for w in sentences.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_vocab = ['<unk>'] + [w for w, cnt in c.most_common() if cnt > 2]\n",
    "vocab = dict([(w, i) for i, w in enumerate(inv_vocab)])\n",
    "word_ids = [vocab[w] for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print u'全部的字數:', len(words)\n",
    "print u'字典的字數:', len(vocab)\n",
    "print u'最常見的單字:', c.most_common()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW (continuous bag-of-words)\n",
    "\n",
    "![CBOW](http://sebastianruder.com/content/images/2016/02/cbow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbow = []\n",
    "win = 2\n",
    "for i in range(win, len(word_ids) - win):\n",
    "    x = tuple([word_ids[j] for j in range(i - win, i + win + 1) if j != i])\n",
    "    cbow.append((x, word_ids[i]))\n",
    "print cbow[0], len(cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram\n",
    "\n",
    "![](http://sebastianruder.com/content/images/2016/02/skip-gram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skipgram = []\n",
    "win = 3\n",
    "for i in range(win, len(word_ids) - win):\n",
    "    skipgram.extend([(word_ids[i], word_ids[j])\n",
    "                     for j in range(i - win, i + win + 1) if j != i])\n",
    "print skipgram[0], len(skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_sim(word):\n",
    "    vw = np.expand_dims(word_vector[vocab[word]], 0)\n",
    "    sim = np.argsort((1 - cdist(word_vector, vw, 'cosine')).flatten())[::-1]\n",
    "    return [inv_vocab[i] for i in sim[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skipgram_batch(size):\n",
    "    index = range(len(skipgram))\n",
    "    np.random.shuffle(index)\n",
    "    for e in range(size, len(skipgram), size):\n",
    "        s = e - size\n",
    "        x_data = [skipgram[i][0] for i in index[s:e]]\n",
    "        y_data = [[skipgram[i][1]] for i in index[s:e]]\n",
    "        yield x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "vector_size = 10\n",
    "X = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "Y = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    wordvec = tf.Variable(tf.random_normal([len(vocab), vector_size]))\n",
    "    vec_X = tf.nn.embedding_lookup(wordvec, X)\n",
    "\n",
    "    nce_weights = tf.Variable(tf.random_normal([len(vocab), vector_size]))\n",
    "    nce_biases = tf.Variable(tf.zeros([len(vocab)]))\n",
    "\n",
    "nce_loss = tf.nn.nce_loss(nce_weights, nce_biases, vec_X, Y, 10, len(vocab))\n",
    "loss = tf.reduce_mean(nce_loss)\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "rate = tf.train.exponential_decay(0.1, global_step, 100000, 0.9, staircase=True)\n",
    "train_op = tf.train.AdadeltaOptimizer(rate).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(50):\n",
    "        losses = []\n",
    "        for x, y in skipgram_batch(batch_size):\n",
    "            _, loss_val = sess.run([train_op, loss], feed_dict={X: x, Y: y})\n",
    "            losses.append(loss_val)\n",
    "        word_vector = sess.run(wordvec)\n",
    "        print epoch, np.mean(losses)\n",
    "        print '    she --> ', most_sim('she')\n",
    "        print '    office --> ', most_sim('office')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "vec_2d = tsne.fit_transform(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "for i, word in enumerate(inv_vocab):\n",
    "    x, y = vec_2d[i]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
