{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_text_to_id(filename):\n",
    "    with open(filename) as f:\n",
    "        text = f.read().decode('utf8').replace(u'ã€€', '').replace(u'\\n', '')\n",
    "        words = list(text)\n",
    "    vocab = ['<unk>'] + sorted(list(set(words)))\n",
    "    vocab = dict(zip(vocab, range(len(vocab))))\n",
    "    word_ids = [vocab[w] if w in vocab else 0 for w in words]\n",
    "    inv_vocab = np.array([x[1] for x in sorted(zip(vocab.values(), vocab.keys()))])\n",
    "    return word_ids, vocab, inv_vocab\n",
    "\n",
    "word_ids, vocab, inv_vocab = load_text_to_id('raw_novel.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch(word_ids, batch_size, n_steps):\n",
    "    word_ids = np.array(word_ids)\n",
    "    batch_count = len(word_ids) // batch_size\n",
    "    data = word_ids[:batch_count*batch_size].reshape([batch_size, batch_count])\n",
    "    for end in range(n_steps, batch_count, 1):\n",
    "        start = end - n_steps\n",
    "        x = data[:, start:end]\n",
    "        y = data[:, (start+1):(end+1)]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(scope_name, n_steps, dim_input, dim_hidden, batch_size, vocab_size, n_layer=1):\n",
    "    input_data = tf.placeholder('int32', [batch_size, n_steps])\n",
    "    targets = tf.placeholder('int32', [batch_size, n_steps])\n",
    "    p_keep = tf.placeholder_with_default(tf.constant(1.0), [])\n",
    "\n",
    "    with tf.variable_scope(scope_name) as scope:\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            try:\n",
    "                embedding = tf.get_variable('embedding', [vocab_size, dim_input],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "            except ValueError:\n",
    "                scope.reuse_variables()\n",
    "                embedding = tf.get_variable('embedding', [vocab_size, dim_input],\n",
    "                                            initializer=tf.contrib.layers.xavier_initializer())\n",
    "            inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "            inputs = [tf.squeeze(input_, [1]) for input_ in tf.split(1, n_steps, inputs)]\n",
    "\n",
    "        with tf.device('/gpu:0'):\n",
    "            cell = tf.nn.rnn_cell.GRUCell(dim_hidden)\n",
    "            cell = tf.nn.rnn_cell.DropoutWrapper(cell, p_keep, p_keep)\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell([cell] * n_layer)\n",
    "            initial_state = cell.zero_state(batch_size, 'float32')\n",
    "\n",
    "        outputs, state = tf.nn.rnn(cell, inputs, initial_state=initial_state)\n",
    "        output = tf.reshape(tf.concat(1, outputs), [-1, dim_hidden])\n",
    "        with tf.device('/gpu:0'):\n",
    "            Wy = tf.get_variable('Wy', [dim_hidden, vocab_size],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            by = tf.get_variable('by', [vocab_size],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            logits = tf.matmul(output, Wy) + by\n",
    "            probs = tf.nn.softmax(logits)\n",
    "            loss = tf.nn.seq2seq.sequence_loss_by_example(\n",
    "                [logits], [tf.reshape(targets, [-1])],\n",
    "                [tf.ones([batch_size * n_steps], dtype='float32')], vocab_size)\n",
    "            cost = tf.reduce_sum(loss) / batch_size / n_steps\n",
    "            final_state = state\n",
    "            train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "\n",
    "    return {'train': train_op, 'final_state': final_state, 'cost': cost,\n",
    "            'logits': logits, 'input': input_data, 'target': targets,\n",
    "            'init_state': initial_state, 'cell': cell, 'p_keep': p_keep,\n",
    "            'embedding': embedding, 'probs': probs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(n_steps, dim_input, dim_hidden, batch_size=128, n_layer=1, p_keep=1.0, final_train=False):\n",
    "    batch_size = 128\n",
    "    vocab_size = len(vocab)\n",
    "    if final_train:\n",
    "        scope_name = 'default'\n",
    "    else:\n",
    "        scope_name = 'rnn_{}_{}_{}_{}_{}'.format(n_layer, n_steps, dim_input, dim_hidden, batch_size)\n",
    "    model = get_model(scope_name, n_steps, dim_input, dim_hidden, batch_size, vocab_size, n_layer)\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        X = model['input']\n",
    "        Y = model['target']\n",
    "        dp = model['p_keep']\n",
    "        last_cost = 100.0\n",
    "        for epoch in range(100):\n",
    "            for x, y in batch(word_ids[:100000], batch_size, n_steps):\n",
    "                sess.run(model['train'], feed_dict={X: x, Y: y, dp: p_keep})\n",
    "            cost = []\n",
    "            for x, y in batch(word_ids[100000:], batch_size, n_steps):\n",
    "                cost.append(sess.run(model['cost'], feed_dict={X: x, Y: y, dp: 1.0}))\n",
    "            curr_cost = np.mean(cost)\n",
    "            print epoch, curr_cost\n",
    "            if curr_cost > last_cost or abs(curr_cost - last_cost) < 0.01:\n",
    "                break\n",
    "            last_cost = curr_cost\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        saver.save(sess, './lstm_zh.checkpoint')\n",
    "        return curr_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "1. number of dimensions of input\n",
    "2. number of hidden units\n",
    "3. number of RNN cells\n",
    "\n",
    "```python\n",
    "cost = {}\n",
    "for dim_input in (5, 10, 15, 30, 50, 100):\n",
    "    for dim_hidden in (5, 10, 15, 30, 50, 100):\n",
    "        for n_steps in (20, 60, 100):\n",
    "            print 'dim_input={}, dim_hidden={}, n_steps={}'.format(dim_input, dim_hidden, n_steps)\n",
    "            cost[(n_steps, dim_input, dim_hidden)] = train(n_steps, dim_input, dim_hidden)\n",
    "            print\n",
    "print cost\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_input=5, dim_hidden=5, n_steps=20\n",
      "0 5.74456\n",
      "1 5.55805\n",
      "2 5.43175\n"
     ]
    }
   ],
   "source": [
    "cost = {}\n",
    "for dim_input in (5, 10, 15, 30, 50, 100):\n",
    "    for dim_hidden in (5, 10, 15, 30, 50, 100):\n",
    "        for n_steps in (20, 60, 100):\n",
    "            print 'dim_input={}, dim_hidden={}, n_steps={}'.format(dim_input, dim_hidden, n_steps)\n",
    "            cost[(n_steps, dim_input, dim_hidden)] = train(n_steps, dim_input, dim_hidden)\n",
    "            print\n",
    "print cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result of Grid Search\n",
    "\n",
    "```\n",
    "dim_input=5, dim_hidden=5, n_steps=20, 12 4.81909  \n",
    "dim_input=5, dim_hidden=5, n_steps=60, 10 4.82728  \n",
    "dim_input=5, dim_hidden=5, n_steps=100, 8 4.82829  \n",
    "dim_input=5, dim_hidden=10, n_steps=20, 11 4.54927  \n",
    "dim_input=5, dim_hidden=10, n_steps=60, 8 4.50915  \n",
    "dim_input=5, dim_hidden=10, n_steps=100, 8 4.54042  \n",
    "dim_input=5, dim_hidden=15, n_steps=20, 10 4.41731  \n",
    "dim_input=5, dim_hidden=15, n_steps=60, 8 4.40338  \n",
    "dim_input=5, dim_hidden=15, n_steps=100, 6 4.39306  \n",
    "dim_input=5, dim_hidden=30, n_steps=20, 8 4.3128\n",
    "dim_input=5, dim_hidden=30, n_steps=60, 6 4.34912  \n",
    "dim_input=5, dim_hidden=30, n_steps=100, 4 4.34219  \n",
    "dim_input=5, dim_hidden=50, n_steps=20, 4 4.46443  \n",
    "dim_input=5, dim_hidden=50, n_steps=60, 14 5.31131  \n",
    "dim_input=5, dim_hidden=50, n_steps=100, 17 5.7858  \n",
    "dim_input=5, dim_hidden=100, n_steps=20, 10 5.79669  \n",
    "dim_input=5, dim_hidden=100, n_steps=60, 42 8.45632  \n",
    "dim_input=5, dim_hidden=100, n_steps=100, 41 10.0958  \n",
    "dim_input=10, dim_hidden=5, n_steps=20, 11 4.79327  \n",
    "dim_input=10, dim_hidden=5, n_steps=60, 10 4.78631  \n",
    "dim_input=10, dim_hidden=5, n_steps=100, 10 4.81798  \n",
    "dim_input=10, dim_hidden=10, n_steps=20, 11 4.53468  \n",
    "dim_input=10, dim_hidden=10, n_steps=60, 8 4.49229  \n",
    "dim_input=10, dim_hidden=10, n_steps=100, 7 4.48285  \n",
    "dim_input=10, dim_hidden=15, n_steps=20, 10 4.42211  \n",
    "dim_input=10, dim_hidden=15, n_steps=60, 8 4.35828  \n",
    "dim_input=10, dim_hidden=15, n_steps=100, 7 4.36294  \n",
    "dim_input=10, dim_hidden=30, n_steps=20, 6 4.36829  \n",
    "dim_input=10, dim_hidden=30, n_steps=60, 5 4.31422\n",
    "dim_input=10, dim_hidden=30, n_steps=100, 4 4.31992  \n",
    "dim_input=10, dim_hidden=50, n_steps=20, 5 4.41931  \n",
    "dim_input=10, dim_hidden=50, n_steps=60, 15 5.30443  \n",
    "dim_input=10, dim_hidden=50, n_steps=100, 2 4.49032  \n",
    "dim_input=10, dim_hidden=100, n_steps=20, 25 5.4159  \n",
    "dim_input=10, dim_hidden=100, n_steps=60, 47 8.59541  \n",
    "dim_input=10, dim_hidden=100, n_steps=100, 42 10.0263  \n",
    "dim_input=15, dim_hidden=5, n_steps=20, 11 4.82542  \n",
    "dim_input=15, dim_hidden=5, n_steps=60, 10 4.70664  \n",
    "dim_input=15, dim_hidden=5, n_steps=100, 9 4.79271  \n",
    "dim_input=15, dim_hidden=10, n_steps=20, 10 4.57568  \n",
    "dim_input=15, dim_hidden=10, n_steps=60, 10 4.5129  \n",
    "dim_input=15, dim_hidden=10, n_steps=100, 8 4.51734  \n",
    "dim_input=15, dim_hidden=15, n_steps=20, 9 4.43064  \n",
    "dim_input=15, dim_hidden=15, n_steps=60, 9 4.343  \n",
    "dim_input=15, dim_hidden=15, n_steps=100, 7 4.3824  \n",
    "dim_input=15, dim_hidden=30, n_steps=20, 8 4.32061  \n",
    "dim_input=15, dim_hidden=30, n_steps=60, 5 4.30017  <======== BEST\n",
    "dim_input=15, dim_hidden=30, n_steps=100, 4 4.31141  \n",
    "dim_input=15, dim_hidden=50, n_steps=20, 4 4.44926  \n",
    "dim_input=15, dim_hidden=50, n_steps=60, 13 5.28622  \n",
    "dim_input=15, dim_hidden=50, n_steps=100, 2 4.46069  \n",
    "dim_input=15, dim_hidden=100, n_steps=20, 26 5.39629  \n",
    "dim_input=15, dim_hidden=100, n_steps=60, 63 8.76479  \n",
    "dim_input=15, dim_hidden=100, n_steps=100, 47 10.1521  \n",
    "dim_input=30, dim_hidden=5, n_steps=20, 12 4.834  \n",
    "dim_input=30, dim_hidden=5, n_steps=60, 10 4.80542  \n",
    "dim_input=30, dim_hidden=5, n_steps=100, 9 4.82141  \n",
    "dim_input=30, dim_hidden=10, n_steps=20, 11 4.5351  \n",
    "dim_input=30, dim_hidden=10, n_steps=60, 9 4.45272  \n",
    "dim_input=30, dim_hidden=10, n_steps=100, 7 4.51826  \n",
    "dim_input=30, dim_hidden=15, n_steps=20, 11 4.40718  \n",
    "dim_input=30, dim_hidden=15, n_steps=60, 8 4.36056  \n",
    "dim_input=30, dim_hidden=15, n_steps=100, 8 4.41101  \n",
    "dim_input=30, dim_hidden=30, n_steps=20, 8 4.32665  \n",
    "dim_input=30, dim_hidden=30, n_steps=60, 5 4.34097  \n",
    "dim_input=30, dim_hidden=30, n_steps=100, 4 4.34122  \n",
    "dim_input=30, dim_hidden=50, n_steps=20, 5 4.44636  \n",
    "dim_input=30, dim_hidden=50, n_steps=60, 3 4.4633  \n",
    "dim_input=30, dim_hidden=50, n_steps=100, 2 4.46157  \n",
    "dim_input=30, dim_hidden=100, n_steps=20, 10 5.78953  \n",
    "dim_input=30, dim_hidden=100, n_steps=60, 55 8.77992  \n",
    "dim_input=30, dim_hidden=100, n_steps=100, 41 10.0491\n",
    "dim_input=50, dim_hidden=5, n_steps=20, 12 4.80319\n",
    "dim_input=50, dim_hidden=5, n_steps=60, 8 4.77495\n",
    "dim_input=50, dim_hidden=5, n_steps=100, 9 4.79949\n",
    "dim_input=50, dim_hidden=10, n_steps=20, 12 4.55258\n",
    "dim_input=50, dim_hidden=10, n_steps=60, 10 4.48609\n",
    "dim_input=50, dim_hidden=10, n_steps=100, 8 4.4701\n",
    "dim_input=50, dim_hidden=15, n_steps=20, 11 4.41331\n",
    "dim_input=50, dim_hidden=15, n_steps=60, 9 4.34871\n",
    "dim_input=50, dim_hidden=15, n_steps=100, 6 4.41298\n",
    "dim_input=50, dim_hidden=30, n_steps=20, 8 4.31822\n",
    "dim_input=50, dim_hidden=30, n_steps=60, 5 4.33932\n",
    "dim_input=50, dim_hidden=30, n_steps=100, 24 4.93073\n",
    "dim_input=50, dim_hidden=50, n_steps=20, 5 4.42341\n",
    "dim_input=50, dim_hidden=50, n_steps=60, 17 5.30831\n",
    "dim_input=50, dim_hidden=50, n_steps=100, 15 5.76036\n",
    "dim_input=50, dim_hidden=100, n_steps=20, 10 5.82358\n",
    "dim_input=50, dim_hidden=100, n_steps=60, 50 8.65317\n",
    "dim_input=50, dim_hidden=100, n_steps=100, 34 9.84145\n",
    "dim_input=100, dim_hidden=5, n_steps=20, 12 4.80052\n",
    "dim_input=100, dim_hidden=5, n_steps=60, 10 4.7754\n",
    "dim_input=100, dim_hidden=5, n_steps=100, 10 4.80939\n",
    "dim_input=100, dim_hidden=10, n_steps=20, 11 4.55337\n",
    "dim_input=100, dim_hidden=10, n_steps=60, 9 4.46794\n",
    "dim_input=100, dim_hidden=10, n_steps=100, 8 4.50755\n",
    "dim_input=100, dim_hidden=15, n_steps=20, 11 4.41782\n",
    "dim_input=100, dim_hidden=15, n_steps=60, 8 4.36567\n",
    "dim_input=100, dim_hidden=15, n_steps=100, 6 4.39921\n",
    "dim_input=100, dim_hidden=30, n_steps=20, 7 4.34298\n",
    "dim_input=100, dim_hidden=30, n_steps=60, 5 4.33793\n",
    "dim_input=100, dim_hidden=30, n_steps=100, 4 4.35769\n",
    "dim_input=100, dim_hidden=50, n_steps=20, 5 4.46569\n",
    "dim_input=100, dim_hidden=50, n_steps=60, 13 5.27012\n",
    "dim_input=100, dim_hidden=50, n_steps=100, 24 6.0024\n",
    "dim_input=100, dim_hidden=100, n_steps=20, 11 5.76113\n",
    "dim_input=100, dim_hidden=100, n_steps=60, 45 8.4888\n",
    "dim_input=100, dim_hidden=100, n_steps=100, 36 9.97792\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Grid Search\n",
    "\n",
    "1. number of RNN layers\n",
    "2. probabilities of Dropout\n",
    "\n",
    "```python\n",
    "cost = {}\n",
    "for n_layer in (1, 2, 3):\n",
    "    for p_keep in (0.5, 0.75, 1.0):\n",
    "        print 'n_layer={}, p_keep={}'.format(n_layer, p_keep)\n",
    "        cost[(n_layer, p_keep)] = train(60, 15, 30, n_layer=n_layer, p_keep=p_keep)\n",
    "        print\n",
    "print cost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of Grid Search\n",
    "\n",
    "```\n",
    "n_layer=1, p_keep=0.5, 4.2462716\n",
    "n_layer=1, p_keep=0.75, 4.0205622 <====== BEST\n",
    "n_layer=1, p_keep=1.0, 4.3006234\n",
    "n_layer=2, p_keep=0.5, 5.8313818\n",
    "n_layer=2, p_keep=0.75, 5.8209763\n",
    "n_layer=2, p_keep=1.0, 5.812592\n",
    "n_layer=3, p_keep=0.5, 4.8201237\n",
    "n_layer=3, p_keep=0.75, 5.8212233\n",
    "n_layer=3, p_keep=1.0, 5.8125467\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Grid Search\n",
    "\n",
    "1. number of batches\n",
    "\n",
    "```python\n",
    "cost = {}\n",
    "for b in (32, 64, 96, 128, 192, 256):\n",
    "    print 'batch={}'.format(b)\n",
    "    cost[(n_layer, p_keep)] = train(60, 15, 30, batch_size=b, p_keep=p_keep)\n",
    "    print\n",
    "print cost\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch=32\n",
      "0 5.18427\n",
      "1 4.63354\n",
      "2 4.41146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bcc2e6dab9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'batch={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9bb5fb0fd36b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_steps, dim_input, dim_hidden, batch_size, n_layer, p_keep, final_train)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp_keep\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7.12/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7.12/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7.12/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7.12/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7.12/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cost = {}\n",
    "for b in (32, 64, 96, 128, 192, 256):\n",
    "    print 'batch={}'.format(b)\n",
    "    cost[b] = train(60, 15, 30, batch_size=b, p_keep=0.75)\n",
    "    print\n",
    "print cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.18676\n",
      "1 4.6646\n",
      "2 4.41315\n",
      "3 4.29019\n",
      "4 4.21891\n",
      "5 4.17458\n",
      "6 4.14202\n",
      "7 4.12147\n",
      "8 4.10267\n",
      "9 4.09177\n",
      "10 4.08239\n",
      "11 4.07144\n",
      "12 4.06633\n",
      "13 4.06056\n",
      "14 4.05623\n",
      "15 4.05456\n",
      "16 4.04804\n",
      "17 4.04518\n",
      "18 4.04212\n",
      "19 4.0411\n",
      "20 4.04118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0411777"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(60, 15, 30, 1, 0.75, final_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
